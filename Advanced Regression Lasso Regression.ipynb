{
  "metadata": {
    "kernelspec": {
      "name": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.5.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn import preprocessing\nfrom sklearn import linear_model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport seaborn as sns\nfrom math import log\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n#from subprocess import check_output\n#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "First let's define functions we are going to use. There are three functions:\n\n1. miss_values: to fill in miss values\n\n2. factor_encoding: to transfer factor variables into dummy variables\n\n3. log_skew: log transform columns that are skewed",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def miss_values(df):\n    for column in df:\n        # Test whether column has null value\n        if len(df[column].apply(pd.isnull).value_counts()) > 1:\n            print(column+\" has missing value\")\n            #if column is numeric, fill null with mean\n            if df[column].dtype in ('int64','float64'):\n                df[column] = df[column].fillna(df[column].mean())\n            else:\n                df[column] = df[column].fillna(\"unknown\")",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def log_skew(df):\n    for column in df:\n        if df[column].dtype in ('int64','float64') and column != 'SalePrice':\n            old_skew = df[column].skew()\n            if abs(df[column].skew()) > 1.0:\n                df[column] = df[column].apply(lambda x: log(x+1,2))\n                print('the skewness of '+column+\" is reduced from \"+\\\n                      str(old_skew) + \" to \"+str(df[column].skew()))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def factor_encoding(df):\n    for column in df:\n        if df[column].dtype == 'object':\n            df = df.merge(pd.get_dummies(data=df[column],prefix=column),right_index=True,left_index=True)\n            del df[column]\n    return df",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\ntrain['source'] = 1.0\ntest['source'] = 0.0\nalls = pd.concat([train,test],ignore_index=True)\nmiss_values(alls)\nlog_skew(alls)\nalls = factor_encoding(alls)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "alls[0:5]",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "train = alls[alls['source'] == 1.0]\ntrain.drop(['source'],inplace=True,axis=1)\ntest = alls[alls['source'] == 0.0]\ntest.drop(['source'],inplace=True,axis=1)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "x = train.drop(['SalePrice'],axis=1)\nY = train['SalePrice']\nx_test = test.drop(['SalePrice'],axis=1)\nx_train, x_vali, Y_train, Y_vali = train_test_split(x, Y, test_size=0.25, random_state=42)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Lasso Regression\nalpha = [i*0.1 for i in range(0,30)]\nmse_lasso_test = [0]*len(alpha)\nmse_lasso_train = [0]*len(alpha)\npara_retained_lasso = [0]*len(alpha)\nfor i,al in enumerate(alpha):\n    clf_lasso = linear_model.Lasso(alpha=al,max_iter=10000,normalize=True)\n    clf_lasso.fit(x_train,Y_train)\n    Y_predict_lasso = clf_lasso.predict(x_vali)\n    para_retained_lasso[i] = len([i for i in list(clf_lasso.coef_) if i > 0.0])\n    mse_lasso_train[i] = mean_squared_error(Y_train,clf_lasso.predict(x_train))**0.5\n    mse_lasso_test[i] = mean_squared_error(Y_vali,Y_predict_lasso)**0.5",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(mse_lasso_test[0:5])\nprint(mse_lasso_train[0:5])\nprint(para_retained_lasso[0:5])",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "line_lasso_test, = plt.plot(alpha,mse_lasso_test,'g',label='Lasso(test)')\nline_lasso_train, = plt.plot(alpha,mse_lasso_train,'g--',label='Lasso(train)')\nplt.legend(handles=[line_lasso_test,line_lasso_train])\nplt.xlabel('Hiper-parameter: Alpha')\nplt.ylabel('Square-Root MSE')\nplt.title('Tuning the hiper paremeter Alpha(Lasso)')\nplt.show()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "para_retain, = plt.plot(alpha,para_retained_lasso,'r--',label='retained parameters')\nplt.legend(handles=[para_retain])\nplt.xlabel('Alpha')\nplt.ylabel('Number of parameters')\nplt.title('Number of parameters retained')\nplt.show()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "clf = linear_model.Lasso(alpha=20,max_iter=10000,normalize=True)\nclf.fit(x,Y)\ntest_predicted = clf.predict(x_test)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "test['SalePrice'] = test_predicted\nresult = test[['Id','SalePrice']]\nresult.to_csv('submission.csv',index=False)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    }
  ]
}